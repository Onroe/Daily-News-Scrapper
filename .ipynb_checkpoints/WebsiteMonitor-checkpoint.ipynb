{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from urllib.request import urlopen, Request\n",
    "import mysql.connector\n",
    "import sqlalchemy\n",
    "from datetime import date, datetime\n",
    "engine_stmt = 'mysql+pymysql://root:@localhost:3308/pythonlogin'\n",
    "engine = sqlalchemy.create_engine(engine_stmt)\n",
    "currentdate =  date.today()\n",
    "\n",
    "# Create an account on Twilio to get credentials\n",
    "from twilio.rest import Client\n",
    "account_sid = 'ACCOUNTID'\n",
    "auth_token = 'TOKEN'\n",
    "\n",
    "class WebsiteMonitor:\n",
    "\n",
    "   \n",
    "    article_links = []\n",
    "    article_titles = []\n",
    "    article_type = []\n",
    "\n",
    "    def __init__(self):\n",
    "        self.con = mysql.connector.connect(user='root', password='',host='127.0.0.1',database='pythonlogin',port=3308)\n",
    "        self.cursor = self.con.cursor()\n",
    "\n",
    "    def readData(title):\n",
    "        sql = \"\"\"SELECT * FROM websitemonitor WHERE articletitle = %s\"\"\"\n",
    "        value = (title,)\n",
    "        self.cursor.execute(sql,value)\n",
    "        result = cursor.fetchall()\n",
    "        if (len(result) > 0):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        self.con.close()\n",
    " \n",
    "    def writeData(self,title, link, cat, date):    \n",
    "        sql = \"INSERT INTO websitemonitor (articletitle, articlelink, articletype, date) VALUES (%s, %s, %s, %s)\"\n",
    "        value = (title,link,cat, date)\n",
    "        print(\"STORE\")\n",
    "        print(cursor)\n",
    "        self.cursor.execute(sql,value)\n",
    "        self.con.commit()\n",
    "        #connectDb().close()\n",
    "\n",
    "\n",
    "    def createDataframe(titles, links, types):\n",
    "        dataframe = pd.DataFrame(\n",
    "        {'articletitle': titles,\n",
    "        'articlelink': links,\n",
    "        'articletype': types})\n",
    "        #print(dataframe)\n",
    "    \n",
    "\n",
    "    def sendMessage(account_sid, auth_token, text):\n",
    "        client = Client(account_sid, auth_token)\n",
    "        message = client.messages \\\n",
    "                .create(\n",
    "                     body= text,\n",
    "                     from_='+12056192549',\n",
    "                     to='+256708#####'\n",
    "                 )\n",
    "        print(\"message sent\")\n",
    "\n",
    "\n",
    "    def main(self,url):\n",
    "    \n",
    "         headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "         request = Request(url=url,headers=headers)\n",
    "         #Query the website and return the html \n",
    "         page = urlopen(request)\n",
    "         soup1 = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "        #Check all headings\n",
    "         for heading in soup1.find_all([\"h1\", \"h2\", \"h3\"]):\n",
    "                link = heading.find('a', href=True)\n",
    "                name = heading.name\n",
    "                if link:\n",
    "                     if(name == 'h2'):\n",
    "                        article_type.append('Headline')   \n",
    "                        article_titles.append( heading.text.strip())\n",
    "                        article_links.append(url+heading.find('a')['href'])\n",
    "                        if not(readData(heading.text.strip())):  \n",
    "                            writeData(heading.text.strip(),url+heading.find('a')['href'],'Headline',currentdate)\n",
    "                            print(\"New Headline\")\n",
    "                        #sendMessage(account_sid,auth_token,url+heading.find('a')['href'])\n",
    "                \n",
    "                     elif(name =='h3'):\n",
    "                        article_type.append('Top')   \n",
    "                        article_titles.append( heading.text.strip())\n",
    "                        article_links.append(url+heading.find('a')['href'])  \n",
    "                        if not(readData(heading.text.strip())):  \n",
    "                            writeData(heading.text.strip(),url+heading.find('a')['href'],'Top',currentdate)\n",
    "                            print(\"New TopArticle\")\n",
    "                            \n",
    "                         # print(heading.name + ' ' + heading.text.strip() + url+heading.find('a')['href'])\n",
    "    \n",
    "    #createDataframe(article_titles, article_links, article_type)\n",
    "\n",
    "app = WebsiteMonitor()\n",
    "url = \"https://www.monitor.co.ug\"\n",
    "app.main(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
